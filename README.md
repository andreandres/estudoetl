üöÄ Pipeline ETL com Python e Pandas
Este projeto √© um estudo pr√°tico de Engenharia de Dados que implementa um processo de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) consumindo dados da API p√∫blica DummyJSON. O objetivo √© demonstrar a automa√ß√£o na coleta de dados brutos e a sua posterior convers√£o para formatos estruturados.

üèóÔ∏è Estrutura do Pipeline
O projeto foi dividido nas seguintes etapas l√≥gicas:

Extra√ß√£o (extract_data): Realiza requisi√ß√µes GET para os endpoints da API, tratando poss√≠veis erros de conex√£o.

Carga Inicial (load_data & loop_load_data): Salva os dados brutos em formato .json dentro da pasta data/, simulando uma camada de Data Lake (Raw/Bronze).

Transforma√ß√£o (transform_data_json_to_csv): Utiliza a biblioteca Pandas para ler os arquivos JSON, process√°-los em um DataFrame e export√°-los como arquivos .csv na pasta curated/ (camada de dados limpos/Silver).

üõ†Ô∏è Tecnologias e Bibliotecas
Python 3.x.

Requests: Para consumo da API REST.

Pandas: Para manipula√ß√£o e transforma√ß√£o de dados estruturados.

JSON: Para manipula√ß√£o de arquivos de dados semi-estruturados.
